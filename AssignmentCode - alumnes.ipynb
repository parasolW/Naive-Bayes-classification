{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes i Classificaci√≥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest tercer lliurament es programar√† un classificador, que donat un tweet el categoritzar√† en una de les possibles classes. En aquesta ocasi√≥, implementareu un classificador amb tweets de pol√≠tics.\n",
    "\n",
    "\n",
    "**Qu√® s‚Äôha de fer?**\n",
    "\n",
    "Volem classificar tweets corresponents a diferents politics segons a quin partit pol√≠tic pertanyen. \n",
    "A partir de tots els tweets que tenim, crearem un vector de caracter√≠stiques que ens descrigui cada un dels tweets. \n",
    "Finalment desenvoluparem un classificador probabil√≠stic del tipus Naive Bayes que ens permeti identificar a quin partit pol√≠tic pertany un tweet donat segons les caracter√≠stiques triades.\n",
    "\n",
    "\n",
    "**Quina √©s la idea del sistema de classificaci√≥ que s‚Äôha de desenvolupar?**\n",
    "\n",
    "El classificador √©s un concepte de l'aprenentatge autom√†tic supervisat. \n",
    "L'objectiu del classificador √©s donat un vector de caracter√≠stiques que descriuen els objectes que es volen classificar indicar a quina categoria o classe pertanyen d'entre un conjunt predeterminat. \n",
    "El proc√©s de classificaci√≥ consta de dues parts: \n",
    "(a) el proc√©s d'aprenentatge i \n",
    "(b) el proc√©s d'explotaci√≥ o testeig. \n",
    "El proc√©s d'aprenentatge rep exemples de parelles $(x,y)$ on $x$ s√≥n les caracter√≠stiques, usualment nombres reals, i $y$ √©s la categoria a la que pertanyen. \n",
    "Aquest conjunt se'l coneix com a conjunt d'entrenament i ens servir√† per trobar una funci√≥ $\\hat{y}=h(x)$ que donada una $x$ aconsegueixi que $\\hat{y}=y$. Per altra banda el proc√©s de testeig aplica la funci√≥ $h(x)$ apresa a l'entrenament a una nova descripci√≥ per veure quina categoria li correspon.\n",
    "\n",
    "\n",
    "**Classificaci√≥ i llenguatge natural**\n",
    "\n",
    "La descripci√≥ dels exemples en caracter√≠stiques √©s el punt m√©s cr√≠tic de tot sistema d'aprenentatge autom√†tic. \n",
    "Una de les representacions m√©s simples per tal de descriure un text √©s la representaci√≥ *bag-of-words*.\n",
    "Aquesta representaci√≥ converteix un text en un vector de $N$ paraules. \n",
    "Consisteix en seleccionar un conjunt d'$N$ paraules i per cada paraula comptar quants cops apareix en el text. \n",
    "Una versi√≥ alternativa d'aquest proc√©s pot ser simplement indicar si apareix o no en el text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abans de comen√ßar\n",
    "\n",
    "\n",
    "**\\+ Durant la pr√†ctica, solament es podran fer servir les seg√ºents llibreries**:\n",
    "\n",
    "`Pandas, Numpy` i `NLTK`\n",
    "\n",
    "*Nota: A m√©s de les que ja es troben presents en la 1a cel¬∑la i funcions natives de Python*\n",
    "\n",
    "**\\+ No es poden modificar les definicions de les funcions donades, ni canviar els noms de les variables i par√†metres ja donats**\n",
    "\n",
    "Aix√≤ no implica per√≤ que els h√†giu de fer servir. √âs a dir, que la funci√≥ tingui un par√†metre anomenat `df` no implica que l'h√†giu de fer servir, si no ho trobeu convenient.\n",
    "\n",
    "**\\+ En les funcions, s'especifica qu√® ser√† i de quin tipus cada un dels par√†metres, cal respectar-ho**\n",
    "\n",
    "Per exemple (ho posar√† en el pydoc de la funci√≥), `df` sempre ser√† indicatiu del `Pandas.DataFrame` de les dades. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar les dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pickle\n",
    "from os.path import join as path, dirname\n",
    "\n",
    "try:\n",
    "    from IPython.core.display import HTML\n",
    "\n",
    "    def pprint(df):\n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "            display(HTML(pd.DataFrame(df).to_html()))\n",
    "except:\n",
    "    def pprint(df):\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following command must be run outside of the IPython shell:\n",
      "\n",
      "    $ pip install xlrd\n",
      "\n",
      "The Python package manager (pip) can only be used from outside of IPython.\n",
      "Please reissue the `pip` command in a separate terminal or command prompt.\n",
      "\n",
      "See the Python documentation for more information on how to install packages:\n",
      "\n",
      "    https://docs.python.org/3/installing/\n"
     ]
    }
   ],
   "source": [
    "pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>martarovira</td>\n",
       "      <td>erc</td>\n",
       "      <td>√öltim acte de campanya! Aqu√≠ tossudament al√ßat...</td>\n",
       "      <td>2017-12-19 20:12:01</td>\n",
       "      <td>785</td>\n",
       "      <td>2295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xavierdomenechs</td>\n",
       "      <td>comuns</td>\n",
       "      <td>#Badalona necessita uns pressupostos que posin...</td>\n",
       "      <td>2018-04-27 10:04:19</td>\n",
       "      <td>55</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>albert_rivera</td>\n",
       "      <td>cs</td>\n",
       "      <td>Encuentro Villac√≠s-Valls para lanzar una estra...</td>\n",
       "      <td>2018-11-17 20:34:58</td>\n",
       "      <td>357</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jaumecollboni</td>\n",
       "      <td>psc</td>\n",
       "      <td>‚ÄúLa palabra es como una bala, no tiene retorno...</td>\n",
       "      <td>2018-10-22 18:10:01</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>albiol_xg</td>\n",
       "      <td>ppc</td>\n",
       "      <td>üìª Esta noche, a partir de las 22:10h, me entre...</td>\n",
       "      <td>2018-08-16 10:30:27</td>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 6)\n",
      "Test data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avui hem repr√©s la Comissi√≥ Mixta amb el @gove...</td>\n",
       "      <td>67</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Torra anunci√≥ un \"oto√±o caliente\" para aumenta...</td>\n",
       "      <td>856</td>\n",
       "      <td>1501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dem√† cal sortir als carrers per dir que #Barce...</td>\n",
       "      <td>144</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‚ÄúCerc√†vem or i vam baixar a la mina.\\nI la fos...</td>\n",
       "      <td>338</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Molt senzill d'entendre, companya: \\n1.- L'ALL...</td>\n",
       "      <td>4932</td>\n",
       "      <td>7253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Training data')\n",
    "df_tweets_train = pd.read_excel(path('data', 'train.xlsx'), index_col='Id')\n",
    "pprint(df_tweets_train.head())\n",
    "print(df_tweets_train.shape)\n",
    "\n",
    "print('Test data')\n",
    "df_tweets_test = pd.read_excel(path('data', 'test.xlsx'), index_col='Id')\n",
    "pprint(df_tweets_test.head())\n",
    "print(df_tweets_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementaci√≥\n",
    "\n",
    "Dividirem el notebook en 3 seccions que es complementen una a l'altra:\n",
    "\n",
    "1. An√†lisis de dades: Informaci√≥ b√†sica sobre els tweets\n",
    "2. Processament de les dades: Creaci√≥ d'un vector de caracter√≠stiques a partir dels tweets\n",
    "3. Classificaci√≥ amb Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√†lisis de dades\n",
    "\n",
    "El primer que haurem de fer √©s analitzar les dades mitjan√ßant diferents funcions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tweets(df):\n",
    "    \"\"\"\n",
    "    Retorna el n√∫mero de tweets en el dataframe\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : n√∫mero de tweets\n",
    "    \"\"\"\n",
    "    return df.shape[0]\n",
    "\n",
    "def get_politicians(df):\n",
    "    \"\"\"\n",
    "    Retorna els usuaris dels pol√≠tics que han tuitejat\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : Llista de strings amb els nom dels usuaris\n",
    "    \"\"\"\n",
    "    #utilitzem la funci√≥ unique per evitar usuaris repetits\n",
    "    return df['username'].unique()\n",
    "\n",
    "def count_politicians(df):\n",
    "    \"\"\"\n",
    "    Retorna la quantitat de pol√≠tics que han tuitejat\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : Enter amb la quanitat d'usuaris que han tuitejat\n",
    "    \"\"\"\n",
    "    return len(df['username'].unique())\n",
    "\n",
    "def get_political_party(df):\n",
    "    \"\"\"\n",
    "    Retorna els partits pol√≠tics que han tuitejat\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : Llista de strings amb els nom dels partits pol√≠tics que han tuitejat\n",
    "    \"\"\"\n",
    "    #utilitzem la funci√≥ unique per evitar partits repetits\n",
    "    return df['party'].unique()\n",
    "\n",
    "def count_political_party(df):\n",
    "    \"\"\"\n",
    "    Retorna la quantitat de partits pol√≠tics que han tuitejat\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : Enter amb la quanitat d'usuaris que han tuitejat\n",
    "    \"\"\"\n",
    "    return len(df['party'].unique())\n",
    "\n",
    "def count_tweet_politician(df):\n",
    "    \"\"\"\n",
    "    Retorna la quantitat de tweets per pol√≠tic\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : pd.Series amb la quantitat de tweets per pol√≠tic\n",
    "    \"\"\"\n",
    "    return df.groupby(['username'],sort=False).size()\n",
    "\n",
    "def count_tweet_party(df):\n",
    "    \"\"\"\n",
    "    Retorna la quantitat de tweets per partit pol√≠tic\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : pd.Series amb la quantitat de tweets per partit pol√≠tic\n",
    "    \"\"\"\n",
    "    return df.groupby(['party'],sort=False).size()\n",
    "\n",
    "def top_retweet(df, n):\n",
    "    \"\"\"\n",
    "    Retorna els n tweets que han sigut m√©s retuitejats\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :params n: n√∫mero de tweets per veure\n",
    "    :return : pd.Series amb els top retweets\n",
    "    \"\"\"\n",
    "    return df.sort_values(by=['retweet_count'],ascending=False)[:n]\n",
    "    \n",
    "def top_favorite(df, n):\n",
    "    \"\"\"\n",
    "    Retorna els n tweets m√©s favorits\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :params n: n√∫mero de tweets per veure\n",
    "    :return : pd.Series amb els top favorits\n",
    "    \"\"\"\n",
    "    return df.sort_values(by=['favorite_count'],ascending=False)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920\n",
      "['martarovira' 'xavierdomenechs' 'albert_rivera' 'jaumecollboni'\n",
      " 'albiol_xg' 'miqueliceta' 'quimtorraipla' 'adacolau' 'santirodriguez'\n",
      " 'krls' 'joantarda' 'inesarrimadas'] 12\n",
      "['erc' 'comuns' 'cs' 'psc' 'ppc' 'jxcat'] 6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAFZCAYAAACWmOQIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmYZVV59v/vDe0EyCSNYW70hwNOgM2gEMOQOCKQIApBbQ2vvBpU1BgFjQGnBDXOMyqKigMgBsQBEBlFwGZGwUDAoQXtdgB5VZDh/v2x9qFPF9VV3XX22sXZfX+uq6+qs8/w7Oo69Zy11/As2SYiIvprtdk+gYiIqCuJPiKi55LoIyJ6Lok+IqLnkugjInouiT4ioueS6CMiei6JPiKi55LoIyJ6Lok+IqLn5sz2CQBssMEGnjdv3myfRkTEWLnkkkt+Y3vudI+7XyT6efPmsXDhwtk+jYiIsSLpZyvyuHTdRET0XBJ9RETPJdFHRPRcEn1ERM8l0UdE9FwSfUREzyXRR0T0XBJ9RETP3S8WTK3KnnDsE2b0vKsWXNXymUREX6VFHxHRc0n0ERE9l0QfEdFz6aOPiFXSvMO+OaPn/fSo57R8JvWlRR8R0XPTtuglHQPsCSy2/fih468CXgncBXzT9hua44cDBwF3A6+2fVqNE4/x8NGXf29GzzvkE7u3fCYRq64V6br5HPAR4PODA5J2A/YGnmj7DkkbNse3BvYHHgdsDHxX0qNs3932iUfcHyw67LwZPW/To/56pZ9z5JFHzijWTJ8X/TFt143tc4HfTTj8CuAo23c0j1ncHN8b+IrtO2zfCFwP7NDi+UZExEqa6WDso4C/lvRO4Hbg9bZ/CGwCXDj0uEXNsYhOvPcFe87oef/y1VNbPpOI+4+ZJvo5wHrATsD2wPGSHgFoksd6sheQdDBwMMDmm28+w9OIiIjpzDTRLwJOsm3gYkn3ABs0xzcbetymwE2TvYDto4GjAebPnz/ph0FEzJ4zv/fIGT1vj93/t+UziVHNNNH/N7A7cLakRwEPBH4DnAJ8SdL7KIOxWwEXt3GinTlynRk+79Z2z6OSax7z2Bk977HXXtPymUREV1ZkeuWXgV2BDSQtAo4AjgGOkXQ18BdgQdO6/5Gk44EfU6ZdHpIZNxERs2vaRG/7gOXc9cLlPP6dwDtHOamIWPX81VmXz+h5v9ptm5bPpH/u9yUQVqVlyhERNaQEQkREzyXRR0T0XBJ9RETPJdFHRPRcEn1ERM/d72fdRET0wWzOIEyLPiKi55LoIyJ6Lok+IqLnkugjInouiT4ioueS6CMiei6JPiKi55LoIyJ6Lok+IqLnpk30ko6RtLjZTWrifa+XZEkbNLcl6UOSrpd0paTtapx0RESsuBVp0X8OeObEg5I2A/4O+PnQ4WdR9ondCjgY+PjopxgREaOYNtHbPhf43SR3vR94A+ChY3sDn3dxIbCupI1aOdOIiJiRGfXRS9oL+KXtKybctQnwi6Hbi5pjk73GwZIWSlq4ZMmSmZxGRESsgJVO9JLWAN4M/Ptkd09yzJMcw/bRtufbnj937tyVPY2IiFhBMylT/EhgS+AKSQCbApdK2oHSgt9s6LGbAjeNepIRETFzK92it32V7Q1tz7M9j5Lct7P9K+AU4MXN7JudgFtt39zuKUdExMpYkemVXwZ+ADxa0iJJB03x8G8BNwDXA58C/rmVs4yIiBmbtuvG9gHT3D9v6HsDh4x+WhER0ZasjI2I6Lkk+oiInkuij4jouST6iIieS6KPiOi5JPqIiJ5Loo+I6Lkk+oiInkuij4jouST6iIieS6KPiOi5JPqIiJ5Loo+I6Lkk+oiInkuij4jouRXZeOQYSYslXT107D2SrpV0paSvS1p36L7DJV0v6SeSnlHrxCMiYsWsSIv+c8AzJxw7A3i87ScC/wMcDiBpa2B/4HHNcz4mafXWzjYiIlbatIne9rnA7yYcO932Xc3NCymbgAPsDXzF9h22b6RsKbhDi+cbERErqY0++n8Cvt18vwnwi6H7FjXHIiJiloyU6CW9GbgLOG5waJKHeTnPPVjSQkkLlyxZMsppRETEFGac6CUtAPYEDmw2BYfSgt9s6GGbAjdN9nzbR9ueb3v+3LlzZ3oaERExjRkleknPBN4I7GX7T0N3nQLsL+lBkrYEtgIuHv00IyJipuZM9wBJXwZ2BTaQtAg4gjLL5kHAGZIALrT9cts/knQ88GNKl84htu+udfIRETG9aRO97QMmOfyZKR7/TuCdo5xURES0JytjIyJ6Lok+IqLnkugjInouiT4ioueS6CMiei6JPiKi55LoIyJ6Lok+IqLnkugjInouiT4ioueS6CMiei6JPiKi55LoIyJ6Lok+IqLnkugjInouiT4iouemTfSSjpG0WNLVQ8fWl3SGpOuar+s1xyXpQ5Kul3SlpO1qnnxERExvRVr0nwOeOeHYYcCZtrcCzmxuAzyLsk/sVsDBwMfbOc2IiJipaRO97XOB3004vDdwbPP9scA+Q8c/7+JCYF1JG7V1shERsfJm2kf/cNs3AzRfN2yObwL8Yuhxi5pjERExS9oejNUkxzzpA6WDJS2UtHDJkiUtn0ZERAzMNNH/etAl03xd3BxfBGw29LhNgZsmewHbR9ueb3v+3LlzZ3gaERExnZkm+lOABc33C4CTh46/uJl9sxNw66CLJyIiZsec6R4g6cvArsAGkhYBRwBHAcdLOgj4ObBf8/BvAc8Grgf+BLy0wjlHRMRKmDbR2z5gOXftMcljDRwy6klFRER7sjI2IqLnkugjInouiT4ioueS6CMiei6JPiKi55LoIyJ6Lok+IqLnkugjInouiT4ioueS6CMiei6JPiKi55LoIyJ6Lok+IqLnkugjInouiT4ioueS6CMiem6kRC/ptZJ+JOlqSV+W9GBJW0q6SNJ1kr4q6YFtnWxERKy8GSd6SZsArwbm2348sDqwP/Au4P22twJ+DxzUxolGRMTMjNp1Mwd4iKQ5wBrAzcDuwInN/ccC+4wYIyIiRjDjRG/7l8B/UTYHvxm4FbgEuMX2Xc3DFgGbTPZ8SQdLWihp4ZIlS2Z6GhERMY1Rum7WA/YGtgQ2BtYEnjXJQz3Z820fbXu+7flz586d6WlERMQ0Rum6+VvgRttLbN8JnAQ8FVi36coB2BS4acRzjIiIEYyS6H8O7CRpDUkC9gB+DJwFPK95zALg5NFOMSIiRjFKH/1FlEHXS4Grmtc6Gngj8DpJ1wMPAz7TwnlGRMQMzZn+Ictn+wjgiAmHbwB2GOV1IyKiPVkZGxHRc0n0ERE9l0QfEdFzSfQRET2XRB8R0XNJ9BERPZdEHxHRc0n0ERE9l0QfEdFzSfQRET2XRB8R0XNJ9BERPZdEHxHRc0n0ERE9l0QfEdFzIyV6SetKOlHStZKukfQUSetLOkPSdc3X9do62YiIWHmjtug/CHzH9mOAJwHXAIcBZ9reCjizuR0REbNkxole0trA02i2CrT9F9u3AHsDxzYPOxbYZ9STjIiImRulRf8IYAnwWUmXSfq0pDWBh9u+GaD5umEL5xkRETM0SqKfA2wHfNz2tsAfWYluGkkHS1ooaeGSJUtGOI2IiJjKKIl+EbDI9kXN7RMpif/XkjYCaL4unuzJto+2Pd/2/Llz545wGhERMZUZJ3rbvwJ+IenRzaE9gB8DpwALmmMLgJNHOsOIiBjJnBGf/yrgOEkPBG4AXkr58Dhe0kHAz4H9RowREREjGCnR274cmD/JXXuM8roREdGerIyNiOi5JPqIiJ5Loo+I6Lkk+oiInkuij4jouST6iIieS6KPiOi5JPqIiJ5Loo+I6Lkk+oiInkuij4jouST6iIieS6KPiOi5JPqIiJ5Loo+I6Lkk+oiInhs50UtaXdJlkk5tbm8p6SJJ10n6arP7VEREzJI2WvSHAtcM3X4X8H7bWwG/Bw5qIUZERMzQSIle0qbAc4BPN7cF7A6c2DzkWGCfUWJERMRoRm3RfwB4A3BPc/thwC2272puLwI2GTFGRESMYMaJXtKewGLblwwfnuShXs7zD5a0UNLCJUuWzPQ0IiJiGqO06HcG9pL0U+ArlC6bDwDrSprTPGZT4KbJnmz7aNvzbc+fO3fuCKcRERFTmXGit3247U1tzwP2B75n+0DgLOB5zcMWACePfJYRETFjNebRvxF4naTrKX32n6kQIyIiVtCc6R8yPdtnA2c3398A7NDG60ZExOiyMjYioueS6CMiei6JPiKi55LoIyJ6Lok+IqLnkugjInouiT4ioueS6CMiei6JPiKi55LoIyJ6Lok+IqLnkugjInouiT4ioueS6CMiei6JPiKi50bZM3YzSWdJukbSjyQd2hxfX9IZkq5rvq7X3ulGRMTKGqVFfxfwL7YfC+wEHCJpa+Aw4EzbWwFnNrcjImKWjLJn7M22L22+vw24BtgE2Bs4tnnYscA+o55kRETMXCt99JLmAdsCFwEPt30zlA8DYMM2YkRExMyMnOglrQV8DXiN7T+sxPMOlrRQ0sIlS5aMehoREbEcIyV6SQ+gJPnjbJ/UHP61pI2a+zcCFk/2XNtH255ve/7cuXNHOY2IiJjCKLNuBHwGuMb2+4buOgVY0Hy/ADh55qcXERGjmjPCc3cGXgRcJeny5tibgKOA4yUdBPwc2G+0U4yIiFHMONHbPh/Qcu7eY6avGxER7crK2IiInkuij4jouST6iIieS6KPiOi5JPqIiJ5Loo+I6Lkk+oiInkuij4jouST6iIieS6KPiOi5JPqIiJ5Loo+I6Lkk+oiInkuij4jouST6iIieS6KPiOi5aole0jMl/UTS9ZIOqxUnIiKmViXRS1od+CjwLGBr4ABJW9eIFRERU6vVot8BuN72Dbb/AnwF2LtSrIiImEKtRL8J8Iuh24uaYxER0THZbv9Fpf2AZ9j+P83tFwE72H7V0GMOBg5ubj4a+MkMQm0A/GbE0028xOtDvD7/bIm3fFvYnjvdg+bM4IVXxCJgs6HbmwI3DT/A9tHA0aMEkbTQ9vxRXiPxEq8P8fr8syXe6Gp13fwQ2ErSlpIeCOwPnFIpVkRETKFKi972XZJeCZwGrA4cY/tHNWJFRMTUanXdYPtbwLdqvX5jpK6fxEu8HsXr88+WeCOqMhgbERH3HymBEBHRc0n0ERE9V62PPiJi3EjaEHjw4Lbtn8/i6bRmbBN9178QSesBm9m+smacLkg63/Yukm4DhgdpBNj22hVj/8Mkh28FrrK9uFbcGJ2kzwAftn350LEjbR9ZKd4jgUW275C0K/BE4PO2b6kQay/gvcDGwGJgC+Aa4HFtx5oNYzcYu7xfiO3WfyGSzgb2onwgXg4sAc6x/bq2Yw3FnAu8kVIMbviDbPdaMbsk6ZvAU4CzmkO7AhcCjwLeZvsLLcfbCvhP7vv/+Yg24zSxOv3dSfosy35QD+L9U6V4iyirN99n+/PNsUttb1cp3uXAfGAeZar2KcCjbT+7QqwrgN2B79reVtJuwAG2D57mqaPEPBT4LHAb8GlgW+Aw26e3HWsc++jfDuwE/I/tLYE9gO9XirWO7T8A/wB81vaTgb+tFGvgOEpLYkvgrcBPKQvQqpC0uqSNJW0++FcrVuMe4LG297W9LyUp3gHsSEmSbfss8HHgLmA34PNAqx8mQzr93QGnAt9s/p0JrA38v4rxFgNPA/aT9FFJcyhXgbXcY/su4O+BD9h+LbBRpVh32v4tsJqk1WyfBWxTKdbAPzX55enAXOClwFE1Ao1jou/yFzJH0kbA8yl/VF14mO3PUH7Oc5rW2U41Akl6FfBr4AyWJozaP+c8278eur0YeJTt3wF3Voj3ENtnUq5ef9Z0M9S6Oursdwdg+2tD/46jvE8fXyse5f/wD7afS3N1C6xTMd6dkg4AFrD0ffmASrFukbQWcC5wnKQPUhoHNQ0+JJ9NaUheQaUPznHso5/4C1lMvV/I2yiXjOfb/qGkRwDXVYo1MEh2N0t6DqVG0KaVYh1KuRT+baXXn8x5kk4FTmhu7wucK2lNoPW+V+B2SasB1zWrtX8JbFghDnT7u5vMVkDNK7J7y5jYPlLSQqBaNyalhfty4J22b5S0JfDFSrH2Bm4HXgscSPkAe1ulWAOXSDqdcgV4uKSHUq54WzeOffRrAn+mXI0MfiHHdZysqpG0J3AepSjchymX42+13XqtIElnAX/XXB53QpIoXWG7UFov5wNfc6U3oqTtKd0p61K6/dYG3m37ogqxOvvdNfEGg+lqvv4KONz212rEa2JuAWxl+7uS1gBWt31brXh91jRAtgFusH2LpIcBm9SY8DFWib7Zueo027X7yQfx5gIvowwG3Xv1U3Gwa3Xg1bbfX+P1J4n3GUqJ6G9S+skBsP2+ijG3tv3jCcd2tX12pXj72T5humMxPUkvo5QWX9/2I5uB7k/Y3qPlOFcxySDzgO0nthhr4syzibGqzUBr4q9HuRIbHrw/t+04Y9V1Y/tuSX+StI7tWzsIeTKlhfZd4O7awZqfby+gk0QP/Lz598DmXxeOl/R54D2UN/e7KTMrnlIp3uEs7Saa6tiMSfowUyeLV7cVa5LYnSSKxiGU3eMuauJc10xzbtueFV5zUrYfCiDpbZQroi9QrpAOBB5aM7ak/0PpPt2UMqtvJ+AHVBhDGqtE37gduErSGcAfBwcr/TGtYbvGTJCpXCDpI8BXWfbnu7TtQLbfCtD0Ddp2zRkbAzsC7wIuoPwhHQfs3HYQSc+iDHJtIulDQ3etTftjOgtbfr0V0mWiaNxh+y+l9w2aWTetdwnY/lnXV++UjZJ2HLr9cUkXURoitRwKbA9caHs3SY+hzNZq3Tgm+sHskC6cKunZTSXOrjy1+To8EGQq/PFKejylBbN+c/s3wIsrl5S+kzLG8hBKK/RG2zUGoG6iJOC9gEuGjt9GGXBrje1jh29LWrscrt533VmiaJwj6U3AQyT9HfDPwDdqBJqFq/e7JR1I2d/awAHUv4q/3fbtkpD0INvXSnp0jUBj1UfflQmDXGtS+q/vpIOVo12SdAHw5maKKs3qw/+w/dQpnzhazCsoXWJvBx4GfJIyHfF5leI9gNKg2dz2TLarXJlY8ynz9h9Kea/cQpkrfcmUT5x5vB/a3r5ZWLRjs4L0cttVphs3g4cHUeZ9izIj7dMVB9KPp1ylVL96lzQP+CDl6tKUtTmvsf3TtmMNxfw6ZWbRaygNud8DD6iyIGxcEr2k420/f3kDNW0O0MwmSQ8H/gPY2PazJG0NPKWZn912rCtsP2m6Yy3HnG974YRjLxqsiJW0nu3ftxjvucB/AQ+0vaWkbSgrcPdqK8ZQrCuBQ2yf19zeBfhYrfdml4liNkh6PWW+/rC1bX+45TidToJYzjn8DWUG4Xds/6X11x+jRL+R7Zub6V33YftnFWL+PfC9waWjpHWBXW3/d9uxhmJ+m9IqfLPtJzX9oJfZfkKFWF8HLmXpStEXAvNt79N2rJU4p1aX1Eu6hJIEz7a9bXPsyhrJV9L3be883bEaaieKJsaNTN7Iar2cRBPvUmCB7aua2wdQWtk7Tv3MGcU62/aubb/ucmKtP9X9LosHWzU2ffS2b26+/QfgeNu/7CDsEba/PnQOt0g6AqiW6IENbB8v6fAm5l2SavUV/hOlT/ckyqX4uZQW4mxqe2XgXbZvHQwgVnaxpE8CX6YkxBcAZ0vaDtobUF9Ooriq+boW0HqiaAxvXv1gYD+a8Z1Kngec2PSd7wK8mNJtVMP3u5oEQRkzGnQNb065EhNlrcfPKQuoWjU2iX7I2sDpkn5HGTg50csuqW/TZCUiav+f/bFZOGEASTtRqju2rukiebWkdSh1Re4PC1/avsS8WtI/Aqs3875fTZnxU8Ogb/yICcefSrsD6sOJYiIDVVrYkyxK/ICk84F/rxTvBkn7UxpWvwCebvvPNWLR4SQIlxpdSPoEcMpgskczU6zKLKOx6bqZSNITKS2mfSmlTFv/D5J0DGVA7aOUX/qrgPVsv6TtWEMxnwx8iFKz5GpKsaPnVVktV1aNHsPS+cK3UnHwcAXPqe2umzWAN7O0JXga8A7bt7cVY1UxuDJprEZp4b+i7TGdScbhNqS8N++AXo3HXeJSKHH42ELb85f3nBnHGuNE/1eUS8f9gYdW6nNdE3gLSz9lT6fU3fjj8p/VStw5lBWrAn5iu0axr84HD1fwnC4b9KWPC0kvtP1FSZPWfXHdlcZ7USpKQhmHqFaUTqVkxsBdlOqc/9X2bKbljcMN1BiPa+I+h1J/fnjxWbV6N5JOoyzI/CLlg+2FwNNsP6PtWGPXdSPpFZSW/FzgROBlnrCkvi1NQj9M0lodLSYaTD/8KvBV2/9bOdxtgyQPYPv8Zmpp61ZiAKrt5fRnAPu52axCZSXpV1r+Y1qz+Vp1JeVEko6izKM/rjl0qKSdbR9eI57t3Wq87iRxqiTyqTTdKGtQSll/mjI+cHHlsAdQuvkG44DnNsdaN3Yt+ubN/RUP7XJTMdZTKb/0tWxvLulJwP+1/c8VY25B+SB7AaWS3Vcpg8+t7aA1dAn+Isqbe3jw8Pe239xWrKGYgxkbk/YrV5y5cZ8rhHG8aphMc0W2zWDBWTNN8LKK0zknu2K5Fbiki7/HmgYzsYa+rgWcZLvW4G+nxq5Fb/swSU9SKTkLcJ5LHeca3g88g6Y8q+0rJD1t6qeMpmnNvBt4dzN4+BZKyYDVWwzz3gm3hwcPq3zyDwagZsE9kjYffFA2H6S1Fvg8mLKgaOLlf5UieI11WTrLpmZteCh98vNZuhr2OZSNVV4u6QTbNcsF1DYY5P2TpI2B31Jh9sswlaKJb+C+75fUupH0akoFvZOaQ1+UdHTbiygGbP9iwtS86sXNmlV6z6e0sO+mvBla09Ul+PJ02a9MGYg9X9I5ze2nUd4/NXwBuJbSOHgbpTDWNZViQdki8bKm71yUn61Kt03jYcB2g27MZqrxiU3cS6hbF6a2U5t1Mu+hrC0x5Wq+puMoV+x7UuruL+C+C8RaMY5dN1dSVor+sbm9JvCDSoOxJwLvAz5CWYr9asqCov3bjjUU8yLKLjonUPrpb6gQY8rNIioPHk7sVz4AWFirX7mJuQHl9yfKe+U3leJc5rLf6ODy/wGUwlzV9vtV2QFte8rPdpHtX1WMdQ3wpMGCLEkPAi63/dhx7w5TqTVzx+B7Sgv79sGxSjEvsf3k4QV8ks6x/Tdtxxq7Fj3lDT3cqr6b9hfZDLycUv9iE2ARZdbNIZViDSywfW3lGJ0OGk7wbJbtVz4WuIyWW6KSHuNSJGowHnFT83XzpiunxkKYweyoW1QKxv2KspdBFUMrt09pbq8raZ+KK7e/BFwo6eTm9nOBLzeNrSoTIjr0A2CwsO0O4I5mZW6Vjc8bne1INo4t+tdRLnEGI9X7AJ+z/YHZO6vRzeYUvS41V2S7DmbZNLNxzm77ikzSp2y/bMKUwAHXaGWrlA3+GvAE4HOUVapvsf3JtmM18e5TwKx2y7pZ53Hv7mCeULdo3DTTtDehTHH8R5Y2GtembKrymIqxO9uRbOxa9LbfJ+lslr7ZXmr7shqx1O0OU51N0dOy9dnvwxU3yqCjfmXbL2u+djIeoVLZ8Q/NauNzqbQ6dYJOVm5LWtv2H5oP5Rubf4P71neF2iwdegbwEkpLergxdRvwppqBh8ambqVM66xmrFr0zR/TlbZr7nQ/HO8CyifuJQx1F7nSnpzqqIqepAVT3e8J9dUrxK/eryzpH6a63/ZJU90/w5jn2q46K2tCvE5Wbks61faeum9Rs0HZ7i4+1KqStG+tv+spYm5J+Z3NY9mGZPuVVccp0QNIOo6yAXJr88qniFWttvcUMc/qelaMOthhapI+82W03Wcu6bNT3O0aV2WS3kKZpjexMFaVFu+ElduijCG9wxVWbqtMPdusi7+72dAMwO7LfZNuzZWxVwCfoRSku3fzHdvnLPdJM401hon+e5TW4MUs+8dUo774O4AL3OEOU5LeSZkPXb2KnpbdYUqUqV1VdphqpsAe3GWfedeaFu9EvWjxwuS1WfpC0ndoFn+x7NX7xDUnbca8yBVKLk8aawwT/aRTj6p8CpZyAGsCf2n+Vd9hquPBw853mOqaOtrIpelWfIrt77f5utPE7GzBTRPvo5SJDz+s8fqzSdLVXXUJD8X8R8rG7qfTFGyDSo26cUv0qzpJC9rqQ9fs7DD1YMpeo7tQ+nvPo8xuqFJNUt1u5PID209p+3WniHc65crv9QwtuHGlDe0l/Rh4FPAzytXmoOEz9tUkJR0NfNjNJicdxfxPShmS/2Vp102dRt24JXqV+uwfBh4LPJBSGuCPNVrZTb/kgcCWtt8uaTNgI9u1ix1NdU6tlfHVLOwwpbIP6G2U6WxQFkytZ3u/SvEG+6reO+2w1tiLpLcCV1JqpFT/w+pywU3z2p3t7ta15kPs/6PMKLqDDj7EJF0LPNGVdgQbNnbTKymrVPenrBydT9l1ZqtKsT5G+aTdnbKZ9f+jzHDYvlK8FdHm4rDhHaagmx2mHj3hiuGsZlCqls42cgFeR+nqu1vSn6nf1dfJghstrTx6f9iYppZnzULMKyi1ihbXDjSOiR7b10ta3fbdwGebvuYadrS9naTLmri/l/TASrFWVGstxWbOd80585O5TNJOti8EkLQjULNf+3WUonSPlPR9mo1cagSy3fWK43eo7A72LyxdcPPaCnE63/qua4OrEkkbMjTeUdnDgWsl/ZBl++hbn1gyjon+T02yvVzSu4GbWbrYqG13NnPbB63BuQxNg5olrbXo1U2t9kGswa5BDwBeLOnnze0tqLh83valzQB+9Y1cgE4LtnW14MazsPVd15rf23uBjSkt7C0oBekeVzHsxC0nqxnHRP8iyorAV1JaL5tRNgyv4UOUUgsbNtMenwf8W6VYQFlEYfvGKY612frdYJDk4d4rlg1bfP1he1Z63SlJevGEQ9tJwvbnK8SabCOQXWwf1nKcDzPFlV3Flc3b2375UJxvS3p7pVhdezul8N13XQrT7UalTUAGaswUXJ5xTPT72P4gcDulfxlJh1KKj7XK9nGSLqGQZofsAAAPRElEQVTseqQmds2ys1BqpUwcbD0ReHJzTq+8zzNmrrNa7cxe/+7weMqDKb/LS4HWEz3LL9jWaqIHBvVldga2psy8gbK1Zs39fn8j6d9Yduu7iRuGj6s7bf9W0mqSVrN9lqR31Qgk6XzbuzTTtydbadz6mM44JvoF3Depv2SSY235NWUK4BzgIZK2q7R46TGUy8R1JizfX5t6fYZd1mof7ueFpW9wNd9XWVRk+1XDt5s+7S8s5+FtqL4RyGB6raSXALsNuqKarpXTa8RsdLb13Sy4RWVXqfOA4yQtpuyL2zrbuzRfOxvTGZtEL+kASnW5R0garu72UCq1KprL0pdQ5rkOEpMps3Da9mhK98a6lPKvA7dRCqu1zvZ3mpIEg1rtr3WlWu0e2mGqmcWxFd0Neg37E/VmaU1WsK1mYayNKe//wQfLWs2xKppSDodKWhu4p2bJjFmwN6WX4DWUKdXrUDaPqUId1+0am0QPXEAZeN2AZbfCu40yd7mG5wOP7GKeq+2TJZ0KvNH2f9SOB/euE3gm8Ajbb5O0uaQdaq4TUCnleyhlGuDllA+ZC2h5U/CheN9g6Yf0apSujuNrxLL9ZZXKqoOCbW90xY1AgKNY+sEC8DfAkbWCSXoCpctr/eb2byj7J1xdK2ZXbP+xWUW9PaXh+G3b1bqlbN8j6YrhrtOaxmrBVDMD5jTbnYz0S/oa8Arb1ee5DsU8y92V1v04zToBl12C1gNOt11tnUAz+2Z74ELb2zRdVm+1/YJK8YYXD90F/Mz2okqxzrS9x3THWo65MWWCwjWUjd5vsn1upVi9LZkh6fmUbQTPpnxI/zXwr7ZPrBizs7pd49Six/bdkv4kaR3btRa9DBtcil9N5XmuQy6Q9BE6KGrG7KwTuN327ZJQ2b7tWkmPrhWsi5kNKmUd1gA2aD4shzevqNaVspyrox9Qp2sRYM1BkgewfbZKBc0+eDNlVtFiuHcq9XcpEyFqeWvF117GWCX6xu3AVc0c8OFEWGNK2bHAu5hQRrSyQetouH+w1rjAbKwTWKSyCfN/A2dI+j1Lt/lr3SQzG+69i/ZmOPxfSt/uxpQZPQN/oKykruVQll4d7Ta4OqoY7waVUszDJTMmq9g5jlabcOX+Wybf2KUVzd/dW7rqnRjHRP/N5l8XfmN7yt2Y2tZVt02j83UCtv+++fbIpm95HeA7FUO+n7J36xcoyf1A4KG2391WgGa67wclvcr2h9t63RXQ6dURs1MyoyvfkXQa8OXm9v7At2sF67p3Yqz66Lsm6X2ULptTqFxGdChmJ2V1h+I9hqXrBM7sYJ1ApzRJze/JjrUUa3XgOdx384oq+/2qFKV7KeVqYndKaYIH2H52hVirA0fZ/te2X/v+opnWvDPlb+Fc19tkfRDveEp3W/XeibFL9JK2ovSdb82yNbhbn4etWdgkQx2W1W3irUdZXTycmKp9kHWtGUD8KPAVShfOAcAhNQYQJX2LpmuRZXcMqt4X2ww6rwN8p9YsMUnfq/nenw2TLF4aLjFyD2Xq6ntsf6xC7Em39HSFrTzHMdGfT1m08X7KfPOXUn6OzupG1KRuy+pOuk6gT3/MkuZRFtPtTPkZvw+8xvZPK8S6t1xwH0l6L2UNwgks2wJtff/d+wuVyqcX2K7ZJVbdOPbRP8T2mZLkUnHuSEnnUaFAULOK8giWFqk6B3hb5T61LsvqdrZOYLY0CX3vjsJ9W9LTbddcnTqb1qcMUg43BMzSPvveacoi7FrjtbvsnRjHRH97s6rsOkmvBH4J1CrEdQxwNSUhQpmv/FnqFVGDDsvqUn62Tuphd03SG2y/W8spAFZpltaFwNeb9+ed1K9H3ynbfRl4XSm2b6700p9lae/EbjS9EzUCjWPXzfaUxSHrUirOrQ282/ZFFWLdp8ukVjfKhBhz6KCsrqT5wMmUhN/VOoFOSHqu7W80/aCTJfoa1StvAPYBrvK4/WFNYZY+NHtPS3cIu2owBifpPNt/3XascWzRmzJVbgtKbXOATwE1+kb/rFJm9nwASTsDf64Q516aZE9VSbX2VJ2NdQKdsP2N5tsfU+rNzGPp+93UqV55HXB1n5J8YzATa+GUj4qV1VnvxDi26H8C/Cv3ndnQ+r6VkrahJMN1KK3r3wEvsV1t6zt1uKeqKu4ven/R8fvlc5QqnN9m2SukKtMruyZpP9snTHcsVswkvRPrUHonLmw91hgm+vPdlPnsMObaALb/0EGsK7zsnqqTHmspVufrBLrW5ftF0qQTArqYXtkFTbIx/WTHYuU1Lfu1auWYcey6OULSp4EzWTY5tTbyL+l1yzk+iFWzhdblnqrbNl93GjpWq9zCbKn+fhl6zV4k9IlUtgx8NrCJpOGV4mtTqWb7qkDSl4CXA3dT9mtYR9L7bL+n7VjjmOhfCjyG0j8/uBRve4rXYEOAR1NqiQzq3z+Xsuy7dZqFPVU7LrcwW6q/XyR9wPZrtGxJ5Hv1YHD7Jkr//F4su4PVbdTZjHxVsbXtP0g6EPgW8EbK/2/riX4cu27uHaHuINbpwL62b2tuPxQ4wfYzK8TaYqr7K/Up//tyYlXbcKFrXbxfJD3Z9iVatiTyvdzh3qA1SXpArRlgqyJJPwK2Ab4EfMT2ObW6acexRX+hpK1tV2nlTrA5MLyY6C+U2Rs1zMaeqn8c+v7BlB2uelXrhg7eL7Yvab72IqFPYQdJR1KuMuewdJ1AlW0gVwGfBH4KXAGc2zT2qvTRj2OL/hrgkZTyqHew9M3W+vRKSW+mLJb6OuWS/O+Br9r+zwqxbmSKPVW7+GOS9CDgFNvPqB2rKx2/Xwa/w2X0JRFKupbSVXMJpV8ZKKtHZ+2kekbSHNutj3uMY4u+9W6T5bH9zqbI2GABw0ttX1Yp1v1hT9U1qLRJ9yzq7P0CzB/6/sHAfjTb7vXErbarle5d1SyvUi3QeqXasWvRd0Udb947FHfSPVVdYTu6oQFggNUp5RbeZvsjbcdaVc3GdOBaJB1FeZ+cRE+n43apy0q149ii74Q73rx3SJe7Bu059P1dwK9rXDauKiQNzydfjdLCf+hyHj6OBjX8h69c+jYdt0sb2D5e0uEAtu+SdPd0T5qJJPqpbQT8SFL1zXuHdLZr0GAmj6QNKV0NG0ui4w+2PnkvS6+Q7qIMtLW+onm2rCLTcbvUWaXaJPqpzcYCmM72VJW0FyU5bUypYLkFZdbN42rEWwWcyn0H1PfsaKFdJyQ9h/L+GC6r25vpuB3rrFJt+uin0Ux52sr2dyWtAaw+mFffQeyquwZJuoJy2f1d29tK2g04wPbBbcdaFTQrHbenVAQVSxfY/QLGf+WspE9QBux3Az5NSUoX2z5oVk9sjHVWqTaJfvkkvQw4GFjf9iObjQI+UWNgdDZIWmh7fpPwt23GJS62vcNsn9s46nKB3WxQs4PW0Ne1gJNsP322z21cSXoq991juPXKqum6mdohwA7ARQC2r2v6s/viluaP9TzgOEmLSe2SUXS5wG42DEpl/0nSxpRqrltO8fiYgqQvUNZ4XM7SdQlVSmgn0U/tDtt/GfSxNpdZfboE2ovyx3so8EJKkaqx7l6YZV8ALpY0vMCu9Y2eZ9E3mvGj9wCXUn7GT83uKY21+ZR6N9VzShL91M6R9CbgIZL+jrIhyDemec793tDc7l+z7ApcgHdI+h3U2fm+z7pcYDdLrgXutv21ZnHPdpRJAzEzVwN/BdTaqvBe6aOfQrNo6iDg6ZREeBrw6R7uILSMZsrXBR7zne+jXUN987tQVnS+F3iT7R2neWpMQtJZlKJmF1N5K88k+piUpI1cb1PkGEOSLmtmZ/0nZV/cLw2Ozfa5jaMuq50m0U9C0vG2nz+hRMC9ahTEiri/k3QqZV/TvwWeTNk/+eIaZXWjXUn0kxi0ZpdXI75GbfiI+7tmHckzKa356yRtBDzB9umzfGpjZTBGJuk2lm1IDiqrrt16zCT65ZP0WuB427+c7XOJiJip1Wb7BO7n1gZOl3SepEOasqIREWMlLfoVIOmJwAuAfYFFtv92lk8pImKFpUW/YhYDvwJ+C/RpZWxErAKS6Kcg6RWSzgbOBDYAXpYZNxExbrIydmpbAK+xfflsn0hExEylj34FDG3MAZCNOSJirKTrZgqSnivpOuBG4BzKjkHZHDkixkoS/dTeQdmc+39sbwnsAXx/dk8pImLlJNFP7U7bvwVWk7Sa7UERooiIsZHB2KkNNuY4l2zMERFjKoOxU2hqbl9LufI5kLJ/6022T5zVE4uIWAnpupna8cC/Urb5OgHYCviXWT2jiIiVlEQ/tR2BzYALKJsD3ATsPKtnFBGxkpLop3Ynpeb2Qyjz6G+0fc/snlJExMpJop/aDymJfntgF+AASemfj4ixksHYKUiab3vhhGMvsv2F2TqniIiVlUQfEdFz6bqJiOi5JPqIiJ5Loo+I6Lkk+oghklIWJHoniT7GmqR5kq4euv16SUdKerWkH0u6UtJXmvvWlHSMpB9KukzS3s3xl0g6QdI3KJvB7yrpbEknSrpW0nGS1Dz235vnXy3p6KHjZ0t6v6RzJV0jaXtJJ0m6TtI7hs7vhZIulnS5pE9KWr3T/7BYJSXRR18dBmzbbP348ubYm4Hv2d4e2A14j6Q1m/ueAiywvXtze1vgNcDWwCNYuiL6I7a3t/14ykK6PYdi/sX204BPACcDhwCPB14i6WGSHkvZZH5n29tQSmsc2PYPHjFREn301ZWUiqMvZGnF0acDh0m6HDibstp58+a+M2z/buj5F9te1KyEvhyY1xzfTdJFkq4CdgceN/ScU5qvVwE/sn2z7TuAGyilNPYAngz8sDmHPSgfIhFVpT8yxt1dLNtgGWz5+BzgacBewFskPQ4QsK/tnwy/gKQdgT9OeN07hr6/G5gj6cHAx4D5tn8h6ciheMPPuWfC8++h/K0JONb24Sv1E0aMKC36GHe/BjZsukYeROlKWQ3YrNko5g3AusBawGnAq4b61bddyViDpP6bZp+C563k888EntfsQYyk9SVtsZKvEbHS0qKPsWb7TklvAy6i7O17LbA68EVJ61Ba0e+3fYuktwMfAK5skv1PWbaPfbpYt0j6FKVr5qeUWkgrc64/lvRvlAHf1ShF8w4BfrYyrxOxslICISKi59J1ExHRc0n0ERE9l0QfEdFzSfQRET2XRB8R0XNJ9BERPZdEHxHRc0n0ERE99/8DIx+9UJFipfcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>adacolau</td>\n",
       "      <td>comuns</td>\n",
       "      <td>Que una republicana defienda la Rep√∫blica es b...</td>\n",
       "      <td>2018-10-26 22:17:38</td>\n",
       "      <td>11706</td>\n",
       "      <td>26838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>martarovira</td>\n",
       "      <td>erc</td>\n",
       "      <td>A tots els dem√≤crates: no pararem fins que tor...</td>\n",
       "      <td>2017-11-02 17:42:06</td>\n",
       "      <td>10403</td>\n",
       "      <td>19991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>krls</td>\n",
       "      <td>jxcat</td>\n",
       "      <td>Una causa que necessiti ser defensada amb c√∫te...</td>\n",
       "      <td>2018-08-29 20:21:30</td>\n",
       "      <td>10086</td>\n",
       "      <td>20357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>martarovira</td>\n",
       "      <td>erc</td>\n",
       "      <td>.@junqueras President d'un partit amb 86 anys ...</td>\n",
       "      <td>2017-12-13 21:17:18</td>\n",
       "      <td>9445</td>\n",
       "      <td>15947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>krls</td>\n",
       "      <td>jxcat</td>\n",
       "      <td>Perdoneu, per√≤ aix√≤ √©s tan greu que si no hi h...</td>\n",
       "      <td>2018-09-19 20:16:22</td>\n",
       "      <td>8806</td>\n",
       "      <td>12509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>adacolau</td>\n",
       "      <td>comuns</td>\n",
       "      <td>Que una republicana defienda la Rep√∫blica es b...</td>\n",
       "      <td>2018-10-26 22:17:38</td>\n",
       "      <td>11706</td>\n",
       "      <td>26838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>krls</td>\n",
       "      <td>jxcat</td>\n",
       "      <td>Una causa que necessiti ser defensada amb c√∫te...</td>\n",
       "      <td>2018-08-29 20:21:30</td>\n",
       "      <td>10086</td>\n",
       "      <td>20357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>krls</td>\n",
       "      <td>jxcat</td>\n",
       "      <td>Acabo d'arribar a #Esc√≤cia convidat pel F√≤rum ...</td>\n",
       "      <td>2018-08-24 17:55:01</td>\n",
       "      <td>6783</td>\n",
       "      <td>20018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>martarovira</td>\n",
       "      <td>erc</td>\n",
       "      <td>A tots els dem√≤crates: no pararem fins que tor...</td>\n",
       "      <td>2017-11-02 17:42:06</td>\n",
       "      <td>10403</td>\n",
       "      <td>19991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>krls</td>\n",
       "      <td>jxcat</td>\n",
       "      <td>Una gran #Diada2018 per avan√ßar cap a la rep√∫b...</td>\n",
       "      <td>2018-09-11 18:48:43</td>\n",
       "      <td>6372</td>\n",
       "      <td>18950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(count_tweets(df_tweets_train))\n",
    "print(get_politicians(df_tweets_train), count_politicians(df_tweets_train))\n",
    "print(get_political_party(df_tweets_train), count_political_party(df_tweets_train))\n",
    "\n",
    "count_tweet_politician(df_tweets_train).plot.bar()\n",
    "plt.show()\n",
    "\n",
    "count_tweet_party(df_tweets_train).plot.bar()\n",
    "plt.show()\n",
    "\n",
    "pprint(top_retweet(df_tweets_train, 5))\n",
    "pprint(top_favorite(df_tweets_train, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comptar paraules\n",
    "\n",
    "El primer que haurem d'implementar √©s la funci√≥ *normalize* que normalitzar√† les paraules.\n",
    "\n",
    "No modificar la seg√ºent cel¬∑la, s'encarrega de guardar una cach√© de la funci√≥ normalize per accelerar el proc√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memo(f):\n",
    "    class memodict(dict):\n",
    "        def __init__(self, f):\n",
    "            self.f = f\n",
    "        def __call__(self, *args):\n",
    "            return self[args]\n",
    "        def __missing__(self, key):\n",
    "            ret = self[key] = self.f(*key)\n",
    "            return ret\n",
    "        \n",
    "    return memodict(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'informatica'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "@memo\n",
    "\n",
    "def normalize(word):\n",
    "    \"\"\"\n",
    "    Funci√≥ que donada una paraula la normalitzi\n",
    "    Exemple: inFO*Rm√Ä745tica? ---> informatica\n",
    "    \n",
    "    :param word: paraula a normalitzar\n",
    "    :return : paraula normalitzada\n",
    "    \"\"\"\n",
    "    word=word.lower()\n",
    "    word=re.sub('[0-9]', '', word) #eliminar digits\n",
    "    word=re.sub(r'[^\\w]', '', word) #eliminar simbols \n",
    "   #√†√°√¢√£√§√•√®√©√™√´√¨√≠√Æ√Ø√≤√≥√¥√µ√∂√π√∫√ª√º√Ω√ø√ß√±\n",
    "    lista=[('√°','a'),('√†','a'),('√≠','i'),('√©','e'),('√®','e'),('√≤','o'),('√≥','o'),('√∫','u'),('√¢','a'),('√£','a')\n",
    "           ,('√§','a')]\n",
    "    #normalitzar accents\n",
    "    for i in lista:\n",
    "        if i[0] in word:\n",
    "            word = word.replace(i[0],i[1])\n",
    "    return word\n",
    "\n",
    "normalize('inFO*Rm√Ä745tica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['taller', 'dels', 'nous', 'usos', 'de', 'la', 'informatica']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_to_words(sentence):\n",
    "    \"\"\"\n",
    "    Funci√≥ que donada una frase, generi una llista amb totes les seves paraules normalitzades.\n",
    "    \n",
    "    :param sentence: frase a transformar\n",
    "    :return : llista de paraules (no buides) normalitzades\n",
    "    \n",
    "    Exemple: **Taller DELS noUS U**SOS    de la inFO#Rm765√Ätica? ---> \n",
    "        ['taller', 'dels', 'nous', 'usos', 'de', 'la', 'informatica']\n",
    "    \"\"\"\n",
    "    \n",
    "    return [normalize(i) for i in sentence.split()]\n",
    "\n",
    "sentence_to_words('**Taller DELS noUS U**SOS    de la inFO#Rm765√Ätica?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(df):\n",
    "    \"\"\"\n",
    "    Funci√≥ que ha de construir un DataFrame amb √≠ndex les paraules normalitzades,\n",
    "    i columnes n_ocur (nombre de vegades que apareix la paraula a tots els tweets)\n",
    "    i n_tweets (nombre de tweets on apareix la paraula alguna vegada).\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : DataFrame especificat.\n",
    "    \"\"\"\n",
    "    #omplim dades en un diccionari i despres convertirlo en un datafram. \n",
    "    #Aix√≠ √©s molt m√©s eficient que treballar directament amb el dataframe\n",
    "    tweets=df['text']\n",
    "    data=dict()\n",
    "    for tweet in tweets:\n",
    "        aux=sentence_to_words(tweet)\n",
    "        repeat=[] #per no repetir n_tweets\n",
    "        for word in aux:\n",
    "            #si no hi √©s al dict, l'afegim\n",
    "            if word not in data:\n",
    "                data[word]={'n_ocur':1, 'n_tweets':1}\n",
    "                repeat.append(word)\n",
    "            else:\n",
    "            #mirem si hi es al repeat per incrementar n_tweets\n",
    "                if word not in repeat:\n",
    "                    data[word][\"n_tweets\"]+=1\n",
    "                    repeat.append(word)\n",
    "                data[word][\"n_ocur\"]+=1\n",
    "                \n",
    "     #pd.DataFrame(data)\n",
    "    return pd.DataFrame.from_dict(data, orient='index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contar paraules per partit pol√≠tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ultim</th>\n",
       "      <th>acte</th>\n",
       "      <th>de</th>\n",
       "      <th>campanya</th>\n",
       "      <th>aqui</th>\n",
       "      <th>tossudament</th>\n",
       "      <th>al√ßats</th>\n",
       "      <th>i</th>\n",
       "      <th>amb</th>\n",
       "      <th>un</th>\n",
       "      <th>...</th>\n",
       "      <th>aplegaven</th>\n",
       "      <th>cridar</th>\n",
       "      <th>promovem</th>\n",
       "      <th>boicots</th>\n",
       "      <th>pompeu</th>\n",
       "      <th>fabra</th>\n",
       "      <th>trobareu</th>\n",
       "      <th>famoses</th>\n",
       "      <th>pronunciades</th>\n",
       "      <th>prada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comuns</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>506</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>325</td>\n",
       "      <td>87</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>erc</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>357</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>339</td>\n",
       "      <td>88</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jxcat</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>419</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>389</td>\n",
       "      <td>92</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppc</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>467</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 11208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ultim  acte   de  campanya  aqui  tossudament  al√ßats    i  amb   un  \\\n",
       "comuns    1.0   6.0  506       2.0    11          0.0     0.0  325   87  152   \n",
       "cs        0.0   0.0  622       0.0     5          0.0     0.0   11    1  142   \n",
       "erc       1.0   4.0  357       2.0     2          2.0     2.0  339   88   76   \n",
       "jxcat     1.0   2.0  419       3.0     4          0.0     0.0  389   92   95   \n",
       "ppc       0.0   0.0  467       3.0     8          0.0     0.0   45   27   66   \n",
       "\n",
       "        ...    aplegaven  cridar  promovem  boicots  pompeu  fabra  trobareu  \\\n",
       "comuns  ...          0.0     0.0       0.0      0.0     0.0    0.0       0.0   \n",
       "cs      ...          0.0     0.0       0.0      0.0     0.0    0.0       0.0   \n",
       "erc     ...          0.0     0.0       0.0      0.0     0.0    0.0       0.0   \n",
       "jxcat   ...          1.0     1.0       1.0      1.0     1.0    1.0       1.0   \n",
       "ppc     ...          0.0     0.0       0.0      0.0     0.0    0.0       0.0   \n",
       "\n",
       "        famoses  pronunciades  prada  \n",
       "comuns      0.0           0.0    0.0  \n",
       "cs          0.0           0.0    0.0  \n",
       "erc         0.0           0.0    0.0  \n",
       "jxcat       1.0           1.0    1.0  \n",
       "ppc         0.0           0.0    0.0  \n",
       "\n",
       "[5 rows x 11208 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_words_parties(df):\n",
    "    \"\"\"\n",
    "    Funci√≥ que ha de construir un DataFrame amb columnes les paraules normalitzades,\n",
    "    i √≠ndex cadasc√∫n dels partits, contenint el nombre de vegades que cada paraula\n",
    "    ha aparegut a tweets del partit.\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : DataFrame esmentat.\n",
    "    \"\"\"\n",
    "    parties=get_political_party(df)\n",
    "    data=dict()\n",
    "    for party in parties:\n",
    "        tweets=df.loc[(df['party']==party)]['text'] # agafem tots els tweets d'un partit en concret\n",
    "        tmp=dict() #dict tmp que l'afegirem despres al data\n",
    "        for tweet in tweets:\n",
    "            aux=sentence_to_words(tweet) #normalitzar\n",
    "            for word in aux:\n",
    "                if word not in tmp:\n",
    "                    #l'afegim si no esta \n",
    "                    tmp[word]=1\n",
    "                else:\n",
    "                    #el sumem 1 si ja existeix\n",
    "                    tmp[word]+=1\n",
    "        #key=party, value=diccionari de nombre de vegades que cada paraula ha aparegut a tweet del partit.\n",
    "        data[party]=tmp\n",
    "        #return un dataframe i convertir els NAN en 0.\n",
    "    return pd.DataFrame.from_dict(data, orient='index',dtype='int').fillna(0)\n",
    "words_parties = count_words_parties(df_tweets_train)\n",
    "words_parties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paraules m√©s freq√ºents als tweets\n",
    "\n",
    "\n",
    "**El problema de com escollir el vector de carecter√≠stiques**\n",
    "\n",
    "L'elecci√≥ de les paraules que formen el vector de caracter√≠stiques √©s un pas cr√≠tic. \n",
    "En funci√≥ de com de bona sigui aquesta descripci√≥, millor funcionar√† el sistema. \n",
    "Tot i que us deixem a vosaltres la pol√≠tica de creaci√≥ del vector de caracter√≠stiques us donem una d'exemple. \n",
    "Per saber quines paraules fer servir una possible estrat√®gia √©s agafar aquelles paraules que apareixen entre en un 10 i un 50 percent del total (sense tenir en compte el partit). \n",
    "Podeu experimentar variant aquests valors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erc\n"
     ]
    }
   ],
   "source": [
    "index=get_political_party(df_tweets_train)\n",
    "print(index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Paraules que no aporten significat i no volem utilitzar\n",
    "skip_words = [\"la\",\"de\",\"i\",\"a\",\"que\",\"qu√®\",\"√©s\",\"el\",\"les\",\"las\",\"n'\",\"un\",\"una\",\"uns\",\n",
    "              \"unes\",\"pel\",\"pels\",\"ha\",\"han\",\"ens\",\"en\",\"per\",\"ho\",\"y\",\"tu\",\n",
    "              \"del\",\"amb\",\"d\",\"al\",\"lo\",\"\",\"m√©s\",\"com\",\"fer\",\"hem\",\"als\",\"qui\",\"on\",\"para\",\"con\",\n",
    "              \"o\",\"x\",\"t√©\",\"ja\",\"va\",\"vam\",\"has\",\"los\",\"he\",\"tan\",\"hi\",\"es\",\"dels\",\"no\",\"q\",\"els\",\n",
    "              \"por\",\"sobre\",\"nom√©s\",\"us\",\"aix√≤\",\"se\",\"m√°s\",\"su\",\"aquest\",\"aquests\",\"aquesta\",\"to\",\"esta\",\n",
    "              \"mi\",\"van\",\"tot\",\"me\",\"nos\",\"molt\",\"este\",\"como\", \"ni\", \"m\",\"pq\",\"the\", \"of\",\"mas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topNwords(df, words, N, skip=[]):\n",
    "    \"\"\"\n",
    "    Funci√≥ que crea un pd.Series amb √≠ndex cadasc√∫n dels partits,\n",
    "    i values una llista de les N paraules m√©s representatives \n",
    "    (les que apareixen amb m√©s freq√º√®ncia) de cadasc√∫n dels partits pol√≠tics.\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :param words: diccionari amb les paraules i la seva frequencia\n",
    "    :param N: n√∫mero de paraules m√©s representatives que volem considerar\n",
    "    :return : pd.Series resultant.\n",
    "    \"\"\"\n",
    "    '''\n",
    "    1.sort words segons frequencia\n",
    "    2.per a cada partit es crea una llista de les N paraules m√©s representatives.\n",
    "    \n",
    "    '''\n",
    "    aux=words\n",
    "    parties=words.index\n",
    "    data=dict()\n",
    "    all_words=words.columns\n",
    "    for word in skip:\n",
    "        if word in all_words:\n",
    "            aux=aux.drop(word,1)\n",
    "    for party in parties:\n",
    "        data[party]=aux.T.sort_values([party],ascending=False).T.columns[:N]\n",
    "    return pd.Series(data) \n",
    "    \n",
    "\n",
    "top_words = topNwords(df_tweets_train, words_parties, 10, skip_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De cara a millores, tingueu en compte que tamb√© haureu de filtrar aquelles paraules que apareixen en la majoria  de tweets, aix√≠ com tamb√©, les que √∫nicament apareixen en un conjunt molt petit de tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector de Caracter√≠stiques\n",
    "Creeu el vector de caracter√≠stiques necessari per a fer l‚Äôentrenament del Na√Øve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, top_words): \n",
    "    \"\"\"\n",
    "    Funci√≥ que crea un vector de caracter√≠stiques necessari per a l'entrenament del classificador Naive Bayes.\n",
    "    Retorna un DataFrame on cada fila representa el vector de caracter√≠stiques del corresponent tweet.\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :params top_words: ha de ser el pd.Series que retorna topNWords\n",
    "    :return : pd.DataFrame resultant.\n",
    "    \"\"\"\n",
    "    tweets=df['text']\n",
    "    data=dict()\n",
    "    words=set([word for serie in top_words for word in serie])\n",
    "    i=0\n",
    "    aux=df.index.tolist()\n",
    "    #Per cada tweet\n",
    "    for tweet in tweets:\n",
    "        vector=np.zeros(len(words))\n",
    "        #obtenim les paraules\n",
    "        tmp=sentence_to_words(tweet)\n",
    "        j=0\n",
    "        #Per cada paraula\n",
    "        for word in words:\n",
    "            #Si tenim la paraula\n",
    "            if word in tmp:\n",
    "                vector[j]+=1\n",
    "            j+=1\n",
    "        data[aux[i]]=vector\n",
    "        i+=1\n",
    "    #Retornem un dataframe amb les dades obtingudes\n",
    "    return pd.DataFrame.from_dict(data, orient='index',columns=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 700 # Aquest parametre el podem canviar i fer proves per avaluar quin √©s el millor valor.\n",
    "\n",
    "words_parties = count_words_parties(df_tweets_train)\n",
    "top_words = topNwords(df_tweets_train, words_parties, N, skip_words)\n",
    "features = create_features(df_tweets_train, top_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El classificador Na√Øve Bayes\n",
    "\n",
    "Un cop tenim una representaci√≥ necessitem un proc√©s d'aprenentatge que ens permeti passar de la descripci√≥ a una categoria. \n",
    "En aquest lliurament farem servir el classificador Na√Øve Bayes. \n",
    "Aquest classificador forma part de la fam√≠lia de classificadors probabil√≠stics. \n",
    "La sortida d'un classificador probabil√≠stic √©s un valor de probabilitat donat un exemple per cadascuna de les categories. \n",
    "La decisi√≥ final correspon a la categoria amb m√©s probabilitat. \n",
    "\n",
    "\n",
    "Els classificadors probabilistics Bayesians es basen en el teorema de Bayes per realitzar els c√†lculs per trobar la probabilitat condicionada: \n",
    "$$ p(x,y) = p(x|y)p(y) = p(y|x)p(x)$$\n",
    "d'on podem extreure que: \n",
    "$$ p(y|x) = \\frac{p(x|y)p(y)}{p(x)}$$\n",
    "\n",
    "\n",
    "En molts casos $p(y)$ i $p(x)$ s√≥n desconeguts i es consideren equiprobables. \n",
    "Per tant, la decisi√≥ es simplifica a:\n",
    "$$ p(y|x) = c ¬∑ p(x|y)$$\n",
    "\n",
    "\n",
    "Les deduccions fins a aquest punt s√≥n v√†lides per la majoria de classificadors Bayesians. \n",
    "Na√Øve Bayes es distingeix de la resta perqu√® imposa una condici√≥ encara m√©s restrictiva. \n",
    "Considerem $x=(x_1, \\cdots, x_n)$ un conjunt d'$N$ variables aleat√≤ries. \n",
    "Na√Øve Bayes assumeix que totes elles s√≥n independents entre elles i per tant podem escriure:\n",
    "$$p(x_1,x_2,...,x_N | y) = p(x_1|y)p(x_2|y)...p(x_N|y)$$\n",
    "\n",
    "\n",
    "Podem interpretar l'anterior equaci√≥ de la seg√ºent forma: La probabilitat de que el tweet descrit pel vector de caracter√≠stiques (0,1,0,1,1,1) sigui de la classe \"comuns\" √©s proporcional al producte de la probabilitat que la primera paraula del vector no aparegui en els tweets sobre \"comuns\"  per la probabilitat que la segona paraula s√≠ que hi aparegui, etc.\n",
    "\n",
    "\n",
    "**Estimant les probabilitats marginals condicionades**\n",
    "\n",
    "L'√∫ltim pas que ens queda √©s trobar el valor de les probabilitats condicionades. \n",
    "Farem servir la representaci√≥ de $0$'s i $1$'s indicant que la paraula no apareix (0) o s√≠ apareix (1) a al tweet. \n",
    "Per trobar el valor de la probabilitat condicionada farem servir una aproximaci√≥ freq√ºentista a la probabilitat. \n",
    "Aix√≤ vol dir que calcularem la freq√º√®ncia d'aparici√≥ de cada paraula per a cada categoria. \n",
    "Aquest c√†lcul es fa dividint el nombre de tweets de la categoria en que apareix la paraula pel nombre total de tweets d'aquella categoria. \n",
    "\n",
    "En general:\n",
    "$$p(x = \\text{\"badalona\"} | y = C)= \\frac{A}{B} $$\n",
    "on A √©s el n√∫mero de tweets de la categoria C on hi apareix la paraula 'badalona' i B √©s el n√∫mero total de tweets de la categoria C.\n",
    "\n",
    "\n",
    "### Punts d√®bils:\n",
    "\n",
    "**El problema de la probabilitat 0**\n",
    "\n",
    "Si us hi fixeu b√©, la probabilitat pot ser 0 !! \n",
    "Aix√≤ vol dir, que si en el tweet no hi apareix una paraula no pot ser classificada com un partit pol√≠tic.\n",
    "No sembla raonable que s'assigni o no en aquesta categoria segons si en el tweet hi apareix o no una √∫nica paraula. \n",
    "Per tant, el que s'acostuma a fer √©s donar una baixa probabilitat en comptes de zero. \n",
    "Una de les possibles solucions es fer servir la correcci√≥ de Laplace. \n",
    "Seguint l'exemple anterior la correcci√≥ de Laplace √©s\n",
    "$$p(x= \\text{\"badalona\"} | y = 'C' ) = \\frac{A+1}{B+M}$$ \n",
    "on M √©s el nombre de categories\n",
    "\n",
    "**El problema del \"underflow\"**\n",
    "\n",
    "La funci√≥ que hem de calcular en el Naive Bayes √©s un producte. \n",
    "El nombre de caract√©ristiques del vector √©s el nombre de termes del producte. \n",
    "Aquests nombres s√≥n iguals o menors a 1, si els multipliquem tots entre ells el resultat ser√† massa petit per a representar-lo en un nombre de punt flotant i el c√†lcul acabar√† sent redu√Øt a zero. \n",
    "Per solucionar aquest problema en comptes d'operar fent multiplicacions, se sol passar a l'escala logar√≠tmica i all√† operar fent servir sumes en comptes de multiplicacions.\n",
    "\n",
    "### Classificar:\n",
    "\n",
    "Donat un vector de caracter√≠stiques $x=(x_1,...,x_n)$, per classificar el que farem ser√† calcular la probabilitat de pert√†nyer a cada un dels partits pol√≠tics:\n",
    "\n",
    "$$p(\\text{comuns}|x) = p(\\text{comuns})\\prod_{i=1}^np(x_i|\\text{comuns})$$\n",
    "$$\\cdots$$\n",
    "$$p(\\text{psc}|x) = p(\\text{psc})\\prod_{i=1}^np(x_i|\\text{psc})$$\n",
    "\n",
    "I finalment, el tweet √©s del partit de probabilitat m√†xima. Tingues en compte que per $x_i = 0$ s'ha de considerar la probabilitat inversa, √©s a dir, la probabilitat de ser de la clase $C$ quan $x_i = 0$ ve donada per $1 - p(x_i|C)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementeu la funci√≥ d'aprenentatge del classificador Na√Øve Bayes (funci√≥ **naive_bayes_learn()**). La funci√≥ ha de mostrar per pantalla el resultat obtingut \n",
    "L'**error d'entrenament** es troba calculant el percentatge d'errors que s'obtenen quan es fa el testeig amb les mateixes dades utilizades per fer entrenament (aprenentatge). Aquest error es un valor molt optimista de com funcionar√† el clasificador i mai s'ha de prendre com a mesura per comparar clasificadors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_learn(df, feats):\n",
    "    \"\"\"\n",
    "    Funci√≥ que estima les probabilitats marginals condicionades.\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada (atribut party)\n",
    "    :params feats: DataFrame de features de cada tweet.\n",
    "    :return : DataFrame amb les probabilitats marginals condicionades amb la correcci√≥ de Laplace,\n",
    "        on files s√≥n les feature words, i columnes s√≥n els partits.\n",
    "    \"\"\"\n",
    "    parties=get_political_party(df)\n",
    "    data=dict()\n",
    "    for party in parties:\n",
    "        #creem un vector que sera afegit a data al final de cada iteraci√≥\n",
    "        vector=np.zeros(feats.shape[1])\n",
    "        #agafem els tweets\n",
    "        aux=df.loc[(df['party']==party)]['text']\n",
    "        aux_shape=aux.shape[0]\n",
    "        for index in aux.index.tolist():\n",
    "            vector=np.add(vector,feats.iloc[index])\n",
    "        i=0\n",
    "        for element in vector:\n",
    "            #Utilitzem la correcci√≥ de Laplace A+1 / B+M\n",
    "            vector[i]=(element+1)/(aux_shape+count_political_party(df))\n",
    "            i+=1\n",
    "        data[party]=vector\n",
    "    return pd.DataFrame.from_dict(data, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df, split):\n",
    "    \"\"\"\n",
    "    Funci√≥ que separa les dades en training i test\n",
    "    \n",
    "    :param df:\n",
    "    :param split: proporci√≥ de les dades que ser√†n per l'entrenament\n",
    "    :return : retorna dos dataframes corresponents a l'entrenament i al test\n",
    "    \"\"\"\n",
    "    assert split <= 1, 'split must be between 0 and 1'\n",
    "    tweets_len = count_tweets(df)\n",
    "    #dividir df en dos\n",
    "    return (df.loc[:split*tweets_len,:],df.loc[split * tweets_len+1:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(df_train, feat_train, feat_test, df_test=None):\n",
    "    \"\"\"\n",
    "    Funci√≥ que implementa el clasificador Naive_Bayes, √©s a dir entrena amb les\n",
    "    caracter√≠stiques d'entrenament i despr√©s utilitza les probabilitats estimades\n",
    "    per classificar els vectors de test, segons la f√≥rmula\n",
    "    p(C_j|x) = p(C_j) * p(x_1|C_j) * ... * p(x_n|C_j)\n",
    "    i agafant la m√†xima.\n",
    "    \n",
    "    Tingues en compte el problema de l'underflow:\n",
    "    log(p(C_j|x)) = log(p(C_j) * p(x_1|C_j) * ... * p(x_n|C_j)) =\n",
    "                  = log(P(C_j)) + log(p(x_1|C_j)) + ... + log(p(x_n|C_j))\n",
    "                  \n",
    "    I recorda, per x_i = 0 cal considerar 1 - p(x_1|C_j).\n",
    "    \n",
    "    Si df_test no √©s None, ha de calcular l'encert sobre les dades de test. √âs a dir,\n",
    "    despr√©s de classificar feat_test ha de comparar la classificaci√≥ amb la classe\n",
    "    real i dir (print) quin percentatge d'encert ha obtingut.\n",
    "    \n",
    "    :param df_train: DataFrame amb els tweets que s'utilitzaran per l'entrenament\n",
    "    :param feat_train: Diccionari amb els vectors de caracteristiques de cada tweet de l'entrenament\n",
    "    :param feat_test: Diccionari amb els vectors de caracteristiques de cada tweet de test\n",
    "    :param df_test: En cas d'estar disponible (per Kaggle no hi √©s), \n",
    "        DataFrame amb els tweets que s'utilitzaran pel test\n",
    "    \n",
    "    :return : Una serie on l'index correspon amb els indexos de df_test i els valors s√≥n la\n",
    "        classificaci√≥ retornada per Naive Bayes\n",
    "    \"\"\"\n",
    "    learn = naive_bayes_learn(df_train, feat_train) \n",
    "    indexs=feat_test.index\n",
    "    parties = get_political_party(df_train)\n",
    "    data=[]\n",
    "    for index in indexs:\n",
    "        vector_test=feat_test.loc[index]\n",
    "        tmp=[]\n",
    "        #Per cada partit\n",
    "        for party in parties:\n",
    "            #Vector que cont√© les dades del partit\n",
    "            vector_party=learn.loc[party]\n",
    "            #aux = (log(P(C_j)))\n",
    "            aux= np.log(1/(len(vector_party)))\n",
    "            i=0\n",
    "            #Per cada paraula\n",
    "            for word in vector_test.index:\n",
    "                vector_train=vector_party[i]\n",
    "                 # per x_i = 0 cal considerar 1 - p(x_1|C_j).\n",
    "                if vector_test.at[word]==0:\n",
    "                    #vector_train=1-vector_train\n",
    "                    vector_train = 1 - vector_train\n",
    "                    #log(P(C_j)) + log(p(x_1|C_j)) + ... + log(p(x_n|C_j))\n",
    "                aux+=np.log(vector_train)\n",
    "                i+=1\n",
    "            tmp.append((aux,party))\n",
    "        # using max() and itemgetter()\n",
    "        party_max = max(tmp,key=lambda item:item[0])[1]\n",
    "        data.append(party_max)\n",
    "        \n",
    "    if  df_test is not None:\n",
    "        aciertos = 0\n",
    "        v_parties = df_test['party']\n",
    "        for z,vec in enumerate(v_parties):\n",
    "            if data[z] == vec:\n",
    "                aciertos += 1\n",
    "        print(\"Aciertos: \", aciertos, \" de \", len(data), \":\", (aciertos/len(data)), \"correcto\")\n",
    "        \n",
    "    return pd.Series(data, index=feat_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "883"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Insertem mig diccionari en skip_words pel kaggle\n",
    "skip_words = {'', 'neatly', 'en', 'far', 'quizzically', 'strictly', 'always', 'justly', 'briefly',\n",
    "              'gratefully', 'x', 'nuestra', 'fortunately', 'viceversa', 'con', 'usually', 'on', 'aquello',\n",
    "              'adventurously', 'todo', 'yearly', 'sincerament', 'offensively', 'fiercely', 'avui', 'frantically',\n",
    "              'deliberately', 'their', 'despres', 'nadie', 'fatally', 'lightly', 'daintily', 'generally',\n",
    "              'eventualmente', 'hourly', 'bravely', 'per', 'nearly', 'hom', 'merrily', 'bashfully', 'majestically',\n",
    "              'aquellos', 'octavo', 'menys', 's', 'if', 'zealously', 'mine', 'unbearably', 'l', \n",
    "              'sometimes', 'powerfully', 'eixe', 'cuanta', 'meaningfully', 'dalt', 'incluso', 'breument',\n",
    "              'very', 'vivaciously', 'increiblement', 'absolutamente', 'siete', 'si', 'tu', 'diez', 'ese', \n",
    "              'reluctantly', 'she', 'alt', 'queerly', 'nosotros', 'temprano', 'sempre', 'hastily', 'tercero',\n",
    "              'gladly', 'contra', 'tambien', 'sin', 'dificilmente', 'claro', 'kiddingly', 'roughly', 'aquests',\n",
    "              'ls', 'so', 'potentially', 'sense', 'unfortunately', 'della', 'bleakly', 'seis', 'todavia', \n",
    "              'almost', 'knowledgeably', 'defiantly', 'tercio', 'estas', 'nuestro', 'probablement', 'positively',\n",
    "              'gens', 'too', 'yesterday', 'desgraciadamenteabnormally', 'us', 'exacto', 'juntament', 'els',\n",
    "              'mes', 'poca', 'mentre', 'never', 'of', 'our', 'unnecessarily', 'm', 'carefully', 'respectivament',\n",
    "              'coolly', 'randomly', 'until', 'we', 'excessivament', 'reassuringly', 'los', 'aca', 'thoughtfully',\n",
    "              'asi', 'peor', 'estos', 'alguno', 'nueve', 'qui', 'consigo', 'ara', 'frightfully', 'almenys', 'repeatedly',\n",
    "              'adalt', 'seriously', 'menos', 'actually', 'encima', 'noisily', 'uselessly', 'aunque', 'dreamily',\n",
    "              'slowly', 't', 'cruelly', 'verbally', 'alli', 'tard', 'legalmente', 'qualcun', 'reproachfully', \n",
    "              'faithfully', 'hoy', 'naturalment', 'highly', 'reciprocamente', 'officially', 'themselves', 'desde',\n",
    "              'yourself', 'actualmente', 'swiftly', 'varios', 'segons', 'sympathetically', 'certainly', 'mas', \n",
    "              'li', 'quaintly', 'coaxingly', 'unabashedly', 'envers', 'jaggedly', 'before', 'itself', 'briskly', \n",
    "              'hem', 'commonly', 'tal', 'daily', 'y', 'tant', 'i', 'mentrestant', 'pitjor', 'exactly', 'excesivamente',\n",
    "              'septimo', 'quisvulla', 'dimly', 'nunca', 'qualsevol', 'ninguno', 'puede', 'mitjan√ßant', 'though', \n",
    "              'recklessly', 'unaccountably', 'hi', 'millor', 'no', 'oddly', 'necessariament', 'llevat', 'yours', 'hacia', \n",
    "              'atras', 'scarcely', 'via', 'enlloc', 'dearly', 'keenly', 'at', 'sexto', 'energetically', 'knowingly',\n",
    "              'mia', '√ßo', 'unimpressively', 'zestfully', 'uns', 'cascu', 'contigo', 'healthily', 'youthfully', \n",
    "              'enlaire', 'fondly', 'devora', 'seemingly', 'tuya', 'habitualmente', 'mortally', 'conmigo', 'segunda',\n",
    "              'naturally', 'solemnly', 'salvat', 'pel', 'yawningly', 'primera', 'till', 'woefully', 'aqui', \n",
    "              'ninguna', 'yieldingly', 'mi', 'whenever', 'primero', 'tanto', 'joyously', 'wherever', 'alhora',\n",
    "              'aquella', 'salvant', 'finalmente', 'happily', 'queasily', 'to', 'cheerfully', 'lluny', 'mil', 'once', \n",
    "              'bajo', 'you', 'ultimamente', 'malamente', 'altri', 'brevemente', 'gaire', 'ella', 'your', 'enlla', \n",
    "              'worriedly', 'rapidly', 'quant', 'suspiciously', 'be', 'soon', 'lest', 'bitterly', 'madly', 'zestily', \n",
    "              'truly', 'hers', 'cuarto', 'ningun', 'enormously', 'enthusiastically', 'possiblement', 'softly', \n",
    "              'quicker', 'shyly', 'rightfully', 'u', 'upward', 'mockingly', 'la', 'naturalmente', 'inwardly', \n",
    "              'elegantly', 'where', 'annually', 'wholly', 'physically', 'pero', 'greatly', 'doble', 'davall', 'como', \n",
    "              'de', 'when', 'para', 'less', 'unexpectedly', 'aleshores', 'beautifully', 'honestly', 'cleverly', \n",
    "              'noveno', 'alla', 'furiously', 'pues', 'tampoco', 'adelante', 'fairly', 'des', 'fins', 'suyo',\n",
    "              'continuamente', 'qualsevulla', 'innocently', 'se', 'sweetly', 'com', 'calmly', 'yearningly', \n",
    "              'safely', 'poco', 'whilea√ßo', 'often', 'he', 'jo', 'deeply', 'prop', 'excitedly', 'helpfully', \n",
    "              'gracefully', 'despues', 'quizas', 'doubtfully', 'as', 'sinceramente', 'aquell', 'adrede', 'afora',\n",
    "              'ferociously', 'obediently', 'dins', 'mal', 'evenly', 'aquel', 'junt', 'primeramente', 'valiantly', \n",
    "              'algo', 'dema', 'versus', 'enfora', 'aqueixa', 'easily', 'openly', 'perfectly', 'sternly', 'sots', \n",
    "              'kookily', 'joyfully', 'bien', 'them', 'tercera', 'sheepishly', 'aun', 'cuantos', 'ne', 'closely',\n",
    "              'en√ßa', 'well', 'tres', 'decimo', 'obvio', 'tensely', 'massa', 'encara', 'monthly', 'medio', \n",
    "              'foolishly', 'cuatro', 'molt', 'vaguely', 'equally', 'rigidly', 'millon', 'igualmente', 'van', \n",
    "              'nada', 'promptly', 'shakily', 'quinto', 'wetly', 'miserably', 'tecnicament', 'kindheartedly',\n",
    "              'continually', 'desgraciadament', 'aviat', 'durante', 'pq', 'dos', 'devers', 'completamente', \n",
    "              'vam', 'su', 'weakly', 'escaso', 'dels', 'bastante', 'courageously', 'its', 'judgmentally', \n",
    "              'patiently', 'righteously', 'ho', 'overconfidently', 'segun', 'tan', 'em', 'questionably', \n",
    "              'ja', 'surprisingly', 'ya', 'triumphantly', 'thoroughly', 'cautiously', 'loudly', 'poc', \n",
    "              'the', 'tanmateix', 'aqueix', 'mai', 'es', 'her', 'cien', 'afortunadamente', 'blindly', \n",
    "              'allo', 'colorfully', 'obstante', 'debajo', 'heavily', 'theirs', 'ours', 'sino', 'quiza',\n",
    "              'wildly', 'even', 'speedily', 'excepte', 'cap', 'unes', 'jovially', 'ultra', 'arrogantly',\n",
    "              'mientras', 'tuyo', 'sota', 'supposedly', 'me', 'silently', 'vacantly', 'afortunadament', \n",
    "              'regular', 'quickly', 'anteayer', 'myself', 'detras', 'vastly', 'fast', 'mucho', 'loosely', \n",
    "              'mio', 'upbeat', 'or', 'uno', 'evidentment', 'suddenly', 'fer', 'shrilly', 'accidentally', \n",
    "              'smoothly', 'increiblemente', 'prou', 'de√ßa', 'since', 'ellas', 'ha', 'hasta', 'boastfully', \n",
    "              'despacio', 'siquiera', 'n', 'absolutament', 'vainly', 'dempeus', 'baix', 'evidentemente', \n",
    "              'sobretot', 'urgently', 'delante', 'optimistically', 'un', 'really', 'llavors', 'gently', \n",
    "              'intensely', 'obnoxiously', 'terribly', 'durant', 'entre', 'quasi', 'nosotras', 'alguna', \n",
    "              'instantly', 'esto', 'fully', 'lo', 'ante', 'for√ßa', 'endins', 'absentmindedly', 'asimismo',\n",
    "              'usefully', 'politely', 'blissfully', 'gleefully', 'jealously', 'seguramente', 'upright', \n",
    "              'cuantas', 'abajo', 'properly', 'acaso', 'unnaturally', 'te', 'nervously', 'quelcom', 'nos', \n",
    "              'vuestra', 'et', 'geneticamente', 'mechanically', 'qualcuna', 'vuestro', 'enguany', \n",
    "              'punctually', 'solo', 'lazily', 'sens', 'cierto', 'frankly', 'crossly', 'h', 're', 'in', 'muy',\n",
    "              'nomes', 'sleepily', 'pels', 'ademas', 'only', 'cerca', 'mucha', 'broadly', 'clearly', 'gairebe', \n",
    "              'upside', 'willfully', 'eventually', 'sovint', 'juntamente', 'por', 'esta', 'painfully', 'ens', \n",
    "              'wrongly', 'truthfully', 'del', 'cualquiera', 'endarrere', 'tecnicamente', 'quietly', 'tras',\n",
    "              'pronto', 'entonces', 'eixa', 'after', 'diligently', 'seldom', 'loftily', 'ambdues',\n",
    "              'posiblemente', 'warmly', 'tret', 'cadascu', 'delightfully', 'searchingly', 'hungrily',\n",
    "              'd', 'solament', 'suya', 'doncs', 'him', 'lejos', 'herself', 'pro', 'generously', \n",
    "              'unless', 'busily', 'arreu', 'al', 'it', 'enfrente', 'freely', 'les', 'legalment', \n",
    "              'partially', 'interestingly', 'sedately', 'quirkily', 'unethically', 'tot', 'endavant',\n",
    "              'mysteriously', 'luego', 'este', 'habitualment', 'stealthily', 'ell', 'because', \n",
    "              'they', 'playfully', 'pertot', 'malgrat', 'va', 'molta', 'tremendously', 'ni', 'embargo',\n",
    "              'victoriously', 'han', 'wearily', 'successfully', 'tothom', 'ocho', 'obstant', 'o', \n",
    "              'que', 'wonderfully', 'nosaltres', 'una', 'correctly', 'fervently', 'ns', 'lovingly', \n",
    "              'aixo', 'more', 'arran', 'than', 'scarily', 'limply', 'lively', 'necesariamente', \n",
    "              'helplessly', 'quanta', 'respectivamente', 'intently', 'cual', 'his', 'irritably', \n",
    "              'rarely', 'qualcu', 'boldly', 'ambdos', 'greedily', 'q', 'algu', 'regularly', 'mostly',\n",
    "              'aquest', 'segurament', 'readily', 'totalment', 'tenderly', 'res', 'famously', 'ahora', \n",
    "              'continuament', 'dintre', 'awkwardly', 'although', 'rudely', 'esas', 'deceivingly', 'casi', \n",
    "              'ma√±ana', 'separately', 'aquesta', 'has', 'by', 'anxiously', 'afterwards', 'segundo', \n",
    "              'sols', 'especially', 'completament', 'bastant', 'dificilment', 'knavishly', 'prompte',\n",
    "              'frenetically', 'damunt', 'utterly', 'hopelessly', 'likely', 'triple', 'demasiado', 'aprisa',\n",
    "              'el', 'brightly', 'violently', 'tomorrow', 'poorly', 'tanta', 'amb', 'immediately',\n",
    "              'yourselves', 'aquellas', 'underademas', 'las', 'cinco', 'sobre', 'sharply', 'voluntarily',\n",
    "              'altre', 'als', 'inquisitively', 'ellos', 'totalmente', 'viciously', 'potser',\n",
    "              'altra', 'solidly', 'malament', 'geneticament', 'carelessly', 'cuales', 'probablemente',\n",
    "              'longingly', 'selfishly', 'wisely', 'curiously', 'fora', 'antes', 'ahir', 'ahi', 'arriba', \n",
    "              'nicely', 'loyally', 'siempre', 'my', 'extremely', 'mateix', 'ourselves', 'ayer', 'that',\n",
    "              'kindly', 'thankfully', 'ustedes', 'a', 'mediante', 'cabe', 'avall', 'restfully', 'cuanto',\n",
    "              'actualment', 'tarde', 'ningu', 'mejor', 'tightly', 'jubilantly', 'enrere', 'alrededor', \n",
    "              'ultimately', 'jamas','I','ambdos', 'ambdues','mateix', 'mateixa', 'mateixos', 'mateixes',\n",
    "              'sengles','un', 'una', 'dos', 'dues', 'tres', 'quatre','primer', 'segon', 'quart', 'dese',\n",
    "              'mig', 'terc', 'quart', 'cinque','doble', 'triple', 'parell', 'dotzena', 'centenar',\n",
    "              'prou' ,'gens','bastants','gaires','quant', 'quanta', 'quants', 'quantes','tant',\n",
    "              'tanta', 'tants', 'tantes','molt', 'molta', 'molts', 'moltes','poc', 'poca', 'pocs', \n",
    "              'poques',\"em\",\"ens\",\"et\",\"us\",\"li\",\"ho\",\"hi\",\"me\",\"nos\",\"te\",\"vos\",\"lo\",\"la\",\"aquest\",\n",
    "              \"aquesta\",\" aquests\",\"aquestes\",\"usted\",\n",
    "                \"aqueix\", \"aqueixa\",\" aqueixos\",\" aqueixes\",\n",
    "                \"aquell\", \"aquella\", \"aquells\", \"aquelles\",\"mon\", \"ma\", \"mos\", \"mes\", \n",
    "              \"ton\", \"ta\", \"tos\", \"tes\", \"son\", \"sa\", \"sos\",\n",
    "                \"ses\",\"un\", \"una\", \"uns\", \"unes\",\n",
    "                \"algun\", \"alguna\", \"alguns\", \"algunes\",\"altre\", \"altra\", \"altres\",\n",
    "                \"tal\", \"tals\",\n",
    "                \"cert\", \"certa\", \"certs\", \"certes\",\n",
    "                \"mant\", \"manta\", \"mants\", \"mantes\",\n",
    "                \"qualsevol\", \"qualssevol\",\n",
    "                \"qualsevulla\", \"qualssevulla\",\"ells\",\"elles\",\"vosaltres\",\"ell\",\"ella\",\"nosaltres\",\n",
    "                \"voste\",\"vostes\"\n",
    "                \"cap\",\"cada\",\"tot\", \"tota\", \"tots\", \"totes\",\"diversos\", \"diverses\"\n",
    "             }\n",
    "len(skip_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aciertos:  278  de  383 : 0.7258485639686684 correcto\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1537     jxcat\n",
       "1538    comuns\n",
       "1539       erc\n",
       "1540       psc\n",
       "1541       erc\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = split_train_test(df_tweets_train, 0.8)\n",
    "\n",
    "N = 709\n",
    "# Aquest parametre el podeu canviar i fer proves per avaluar quin √©s el millor valor. \n",
    "words_topics = count_words_parties(df_train)\n",
    "top_words = topNwords(df_train, words_topics, N, skip_words)\n",
    "\n",
    "feat_train = create_features(df_train, top_words)\n",
    "feat_test = create_features(df_test, top_words)\n",
    "\n",
    "preds = naive_bayes(df_train, feat_train, feat_test, df_test)\n",
    "    \n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/t/ef3079700f9e49609ff7a2e70c6fc97e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comuns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comuns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jxcat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>erc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 709\n",
    "words_topics = count_words_parties(df_tweets_train)\n",
    "top_words = topNwords(df_tweets_train, words_topics, N, skip_words)\n",
    "\n",
    "feat_train = create_features(df_tweets_train, top_words)\n",
    "feat_test = create_features(df_tweets_test, top_words)\n",
    "\n",
    "result = naive_bayes(df_tweets_train, feat_train, feat_test)\n",
    "result.index.name = 'tweet_id'\n",
    "result.name = 'party'\n",
    "result.to_frame().to_csv('submission.csv')\n",
    "pprint(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CODI PEL KAGGLE\"\"\"\n",
    "df_train, df_test = split_train_test(df_tweets_train, 0.8)\n",
    "\n",
    "words_topics = count_words_parties(df_train)\n",
    "lista=[]\n",
    "for n in range (700,700,1):\n",
    "    top_words = topNwords(df_train, words_topics, n, skip_words)\n",
    "    feat_train = create_features(df_train, top_words)\n",
    "    feat_test = create_features(df_test, top_words)\n",
    "    print(\"\\n\\nN = \")\n",
    "    print(n)\n",
    "    preds = naive_bayes(df_train, feat_train, feat_test, df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"La aleatorietat influeix en els resultats de les prediccions, ya que depenent de la n es\n",
    "seleccionen al reduir les dades obtenim millors o pitjors resultats. \n",
    "I si per millorar les prediccions fem varies prediccions i fem un 'merge' dels resultats?\n",
    "\"\"\"\n",
    "for x in range(840,840):\n",
    "    name = 'submission'+str(x)+'.csv'\n",
    "    words_topics = count_words_parties(df_tweets_train)\n",
    "    top_words = topNwords(df_tweets_train, words_topics, N, skip_words)\n",
    "\n",
    "    feat_train = create_features(df_tweets_train, top_words)\n",
    "    feat_test = create_features(df_tweets_test, top_words)\n",
    "\n",
    "    result = naive_bayes(df_tweets_train, feat_train, feat_test)\n",
    "    result.index.name = 'tweet_id'\n",
    "    result.name = 'party'\n",
    "    result.to_frame().to_csv(name)\n",
    "    #pprint(result.head())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mergeList(product_list):\n",
    "    punctDict = dict()\n",
    "    for _list in product_list:\n",
    "        punctDict[_list] =  punctDict[_list]+1 if _list in punctDict else 1\n",
    "    keys = sorted(punctDict.keys(),key=lambda x:punctDict[x], reverse=True)\n",
    "    result = [key for key in keys]\n",
    "    return result[0]\n",
    "df_list = [pd.read_csv(('submission'+str(x)+'.csv')) for x in range(701,702)]\n",
    "def getSubmission(data_list):\n",
    "    df_submission = pd.DataFrame(columns=['tweet_id', 'party'])\n",
    "    for index,values in data_list[0].iterrows():\n",
    "        #print(index)\n",
    "        listToMerge = []\n",
    "        for df in data_list:\n",
    "            listToMerge.append(df.loc[index,'party'])\n",
    "        #print(listToMerge)\n",
    "        user_recos = mergeList(listToMerge)\n",
    "        #print(user_recos)\n",
    "        df_submission = df_submission.append(\n",
    "            {\n",
    "                'tweet_id': data_list[0].loc[index,'tweet_id'],\n",
    "                'party': user_recos\n",
    "            }, \n",
    "            ignore_index=True)\n",
    "        \n",
    "    return df_submission    \n",
    "\n",
    "df_submission = getSubmission(df_list)\n",
    "\n",
    "df_submission.to_csv('submission.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
